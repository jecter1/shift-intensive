{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d1865d-ef26-413e-a917-542fbdb2f409",
   "metadata": {},
   "source": [
    "# День 1. NLP. Векторизация текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedc686f-d0fb-4ed8-8cf5-e2ac2d4832fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Описание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013caced-d704-4111-9b7d-1e710a23375f",
   "metadata": {},
   "source": [
    "Дано: текст на каком-то языке (ca, de, el, en, ...), написанный на латинице (транслитом)  \n",
    "Найти: язык текста  \n",
    "\n",
    "`data/plain/train/*.txt` - обучающая выборка  \n",
    "`data/plain/test/*.txt` - тестовая выборка  \n",
    "\n",
    "Для начала векторизуем текст при помощи N-грамм:\n",
    "1) Найдем все N-граммы в тексте (мама мыла раму -> {мам, ама, ма_, а_м, _мы, мыл, ...})\n",
    "2) Пронумеруем их\n",
    "3) Для каждого текста подсчитаем число всех N-грамм \n",
    "4) Запишем это в виде вектора $v$, где $v_i$ - число вхождений $i$-й N-граммы в текст"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b86923-6feb-401a-979f-3c7a6ebdbd5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc4895-6dc6-425d-8348-79b243437fc3",
   "metadata": {},
   "source": [
    "Реализуем 2 класса для обработки текстов:\n",
    "1. `TextPreparer`, при помощи которого будем удалять несущественные символы\n",
    "2. `NGramVectorizer`, при помощи которого будем получать вектора для текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3afbb5cd-0cdc-4619-be95-bfa989c86d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import typing as t\n",
    "from collections.abc import Iterable\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "021bea61-67b5-4401-b24d-09cb5ceb998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\" + os.sep + \"plain\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9fcb3-17ae-43b7-856b-32215b0c9d86",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Считаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7be506f-4765-4786-a446-7450aaebcaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    FILE_POSTFIX = \".txt\"\n",
    "    \n",
    "    def __init__(self, data_path: str):\n",
    "        self.texts = []\n",
    "        self.labels = []\n",
    "        \n",
    "        filenames = os.listdir(data_path)\n",
    "        filenames = list(filter(lambda x: x.endswith(type(self).FILE_POSTFIX), filenames))\n",
    "        \n",
    "        for filename in filenames:\n",
    "            filepath = os.sep.join((data_path, filename))\n",
    "            with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "                text = file.read()\n",
    "            self.texts.append(text)\n",
    "            self.labels.append(filename[:-len(type(self).FILE_POSTFIX)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a542b1c9-0635-40bc-91f8-05bb5d3a549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Data(DATA_PATH + os.sep + \"train\")\n",
    "test_data = Data(DATA_PATH + os.sep + \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47ef8f23-54d5-4cd1-98d5-38ae25bd10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "label_code = dict()\n",
    "for label in train_data.labels:\n",
    "    label_code[label] = counter\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2924a698-b3e9-4f3f-92ca-f9c184abc239",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = list(map(lambda x: label_code[x], train_data.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdb52da1-5007-453c-a58a-153cf70911b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_targets = pd.read_csv(os.sep.join((DATA_PATH, \"test\", \"ans.csv\")), header=None)\n",
    "test_data_targets[1] = test_data_targets[1].apply(lambda x: label_code[x])\n",
    "y_test = list(map(lambda x: test_data_targets.values[int(x)-1][1], test_data.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ca0216-a3d3-4ca8-9ed0-fae5b4c9d800",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### TextPreparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cddb18e3-68d9-47e8-a002-97b100e2d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreparer:\n",
    "    PUNCTUATION_CHARS = (',', ';', '.', ':', '?', '!', '-', '\\n')\n",
    "    \n",
    "    def __init__(self, min_count: int, delete_punct: bool = True):\n",
    "        self.__min_count = min_count\n",
    "        self.__delete_punct = delete_punct\n",
    "        self.__rare_chars = None\n",
    "    \n",
    "    def fit(self, texts: Iterable[str]) -> None:\n",
    "        chars_count = dict()\n",
    "        \n",
    "        for text in texts:\n",
    "            for ch in text:\n",
    "                if ch not in chars_count:\n",
    "                    chars_count[ch] = 1\n",
    "                else:\n",
    "                    chars_count[ch] += 1\n",
    "                    \n",
    "        self.__rare_chars = []\n",
    "        for ch, ch_count in chars_count.items():\n",
    "            if ch_count < self.__min_count:\n",
    "                self.__rare_chars.append(ch)\n",
    "                    \n",
    "    def transform(self, text: str) -> str:\n",
    "        if self.__rare_chars is None:\n",
    "            raise Exception(\"There must be fit() call before transform()\")\n",
    "            \n",
    "        for rare_ch in self.__rare_chars:\n",
    "            text = text.replace(rare_ch, \"\")\n",
    "\n",
    "        if self.__delete_punct:\n",
    "            for punct_ch in type(self).PUNCTUATION_CHARS:\n",
    "                text = text.replace(punct_ch, \"\")\n",
    "        \n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb25ad1-8f74-49fb-9d5d-2b91f32fa6a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### NGramVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2741f32-5894-4bd4-a8bd-d521ef32cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramVectorizer:\n",
    "    def __init__(self, n):\n",
    "        self.__n = n\n",
    "        self.__ngram_number = None\n",
    "        \n",
    "    def __get_ngrams(self, text: str) -> Iterable[str]:\n",
    "        ngrams = []\n",
    "        for i in range(len(text) - self.__n + 1):\n",
    "            ngram = text[i:(i + self.__n)]\n",
    "            ngrams.append(ngram)\n",
    "        return ngrams\n",
    "        \n",
    "    def fit(self, texts: Iterable[str]) -> None:\n",
    "        self.__ngram_number = dict()\n",
    "        cur_number = 0\n",
    "\n",
    "        for text in texts:\n",
    "            for ngram in self.__get_ngrams(text):\n",
    "                if ngram not in self.__ngram_number:\n",
    "                    self.__ngram_number[ngram] = cur_number\n",
    "                    cur_number += 1\n",
    "        \n",
    "    def transform(self, text: str) -> np.ndarray:\n",
    "        if self.__ngram_number is None:\n",
    "            raise Exception(\"There must be fit() call before transform()\")\n",
    "        \n",
    "        res = np.zeros((len(self.__ngram_number),), int)\n",
    "        \n",
    "        for ngram in self.__get_ngrams(text):\n",
    "            if ngram in self.__ngram_number:\n",
    "                res[self.__ngram_number[ngram]] += 1\n",
    "                \n",
    "        res = (res - res.mean()) / res.std()\n",
    "    \n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2caff9-c299-4909-8562-d8b7da7b1343",
   "metadata": {},
   "source": [
    "#### Векторизация текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad97a837-f583-4f72-8f47-74b298e08e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.texts\n",
    "X_test = test_data.texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ca8a1e3-5ff6-4b5c-9ce9-9ee4ee9b7ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preparer = TextPreparer(min_count=100)\n",
    "vectorizer = NGramVectorizer(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a3c82d1-780e-4af8-9387-3c1ad7326a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_preparer.fit(train_data.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cfbef9c-fbed-4fac-a244-42a06b71ccc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_texts = []\n",
    "for text in tqdm(X_train, leave=False):\n",
    "    train_texts.append(text_preparer.transform(text))\n",
    "    \n",
    "X_train = train_texts\n",
    "    \n",
    "test_texts = []\n",
    "for text in tqdm(X_test, leave=False):\n",
    "    test_texts.append(text_preparer.transform(text))\n",
    "    \n",
    "X_test = test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "734382b5-c5c4-422b-ab17-d1de00b5e3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer.fit(train_data.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aad836a-1319-4607-b0c3-dd2eaebbc28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_texts = []\n",
    "for text in tqdm(X_train, leave=False):\n",
    "    train_texts.append(vectorizer.transform(text))\n",
    "    \n",
    "X_train = train_texts\n",
    "    \n",
    "test_texts = []\n",
    "for text in tqdm(X_test, leave=False):\n",
    "    test_texts.append(vectorizer.transform(text))\n",
    "    \n",
    "X_test = test_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d76d87-ba80-493c-b5ed-a98b006d1a38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f75e3ad4-7656-423e-ae4e-c92ad6279951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebd61149-8e3d-47be-8560-ac2b8cf923b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7935bd4e-1a33-4d63-9fcf-931a22c99ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d679bb0-ff82-4e14-a777-79be900c39ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test  accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy: {accuracy_score(y_train_pred, y_train)}\")\n",
    "print(f\"Test  accuracy: {accuracy_score(y_test_pred, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82ba3c1e-5c1a-4920-9704-3031548bac57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  0,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  0,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        0,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  0,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  0,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10,  1,\n",
       "       10, 10, 10, 10, 10, 10, 11, 11, 11, 11,  1, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11,  1, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12,  1, 12,\n",
       "       12, 12, 12, 12, 12, 13, 13, 13, 13,  0,  1, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13,  1, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14,  1, 14,\n",
       "       14, 14, 14, 14, 14, 15, 15, 15, 15,  1, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15,  1, 15,  1,  1,  1,  1,  1,  0,  1,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  0,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  0,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  0,  3,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  0,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  0,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  0,  5,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eafc46cf-124a-4b52-9484-a77eb878f145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  0,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  0,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        0,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  0,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  0,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10,  1,\n",
       "       10, 10, 10, 10, 10, 10, 11, 11, 11, 11,  1, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11,  1, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12,  1, 12,\n",
       "       12, 12, 12, 12, 12, 13, 13, 13, 13,  0,  1, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13,  1, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14,  1, 14,\n",
       "       14, 14, 14, 14, 14, 15, 15, 15, 15,  1, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15,  1, 15,  1,  1,  1,  1,  1,  0,  1,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  0,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  0,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  0,  3,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  0,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  0,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  0,  5,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe0a5045-d0e2-432b-9ff9-6fcf21183412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (y_test != y_test_pred)\n",
    "np.sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c6e97c-c8c6-4314-9e59-af3fd27c2f80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e6c0f56-e972-42a1-af76-860ea337aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text: str) -> str:\n",
    "    text = text_preparer.transform(text)\n",
    "    text = vectorizer.transform(text)\n",
    "    answer_code = clf.predict(text[np.newaxis, :])[0]\n",
    "    for k, v in label_code.items():\n",
    "        if v == answer_code:\n",
    "            return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c90bda2-cea7-4e4c-bc86-251c6a490d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ru'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Eto prostoy primer togo chto vse i tak horosho rabotaet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71b78c9d-4ec6-451c-9aed-d0fbe5a1af11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"This is a simple example of how everything works so well\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49e433-ecee-4546-a649-394b91ec01a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
